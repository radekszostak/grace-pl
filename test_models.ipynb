{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import xgboost as xgb\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "II_112_1_full = \"full_II_112_1.pickle\"\n",
    "II_113_1_full = \"full_II_113_1.pickle\"\n",
    "II_114_1_full = \"full_II_114_1.pickle\"\n",
    "II_131_1_full = \"full_II_131_1.pickle\"\n",
    "II_132_1_full = \"full_II_132_1.pickle\"\n",
    "II_292_1_full = \"full_II_292_1.pickle\"\n",
    "II_297_1_full = \"full_II_297_1.pickle\"\n",
    "II_298_1_full = \"full_II_298_1.pickle\"\n",
    "II_472_1_full = \"full_II_472_1.pickle\"\n",
    "II_924_1_full = \"full_II_924_1.pickle\"\n",
    "II_931_1_full = \"full_II_931_1.pickle\"\n",
    "II_940_1_full = \"full_II_940_1.pickle\"\n",
    "II_952_1_full = \"full_II_952_1.pickle\"\n",
    "II_1345_1_full = \"full_II_1345_1.pickle\"\n",
    "II_1346_1_full = \"full_II_1346_1.pickle\"\n",
    "II_1351_1_full = \"full_II_1351_1.pickle\"\n",
    "II_1352_1_full = \"full_II_1352_1.pickle\"\n",
    "\n",
    "II_112_1_grace = \"grace_II_112_1.pickle\"\n",
    "II_113_1_grace = \"grace_II_113_1.pickle\"\n",
    "II_114_1_grace = \"grace_II_114_1.pickle\"\n",
    "II_131_1_grace = \"grace_II_131_1.pickle\"\n",
    "II_132_1_grace = \"grace_II_132_1.pickle\"\n",
    "II_292_1_grace = \"grace_II_292_1.pickle\"\n",
    "II_297_1_grace = \"grace_II_297_1.pickle\"\n",
    "II_298_1_grace = \"grace_II_298_1.pickle\"\n",
    "II_472_1_grace = \"grace_II_472_1.pickle\"\n",
    "II_924_1_grace = \"grace_II_924_1.pickle\"\n",
    "II_931_1_grace = \"grace_II_931_1.pickle\"\n",
    "II_940_1_grace = \"grace_II_940_1.pickle\"\n",
    "II_952_1_grace = \"grace_II_952_1.pickle\"\n",
    "II_1345_1_grace = \"grace_II_1345_1.pickle\"\n",
    "II_1346_1_grace = \"grace_II_1346_1.pickle\"\n",
    "II_1351_1_grace = \"grace_II_1351_1.pickle\"\n",
    "II_1352_1_grace = \"grace_II_1352_1.pickle\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_dir = \"data/models\"\n",
    "models_300_dir = \"data/models_300\"\n",
    "models_1000_dir = \"data/models_1000\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stations_full = [II_112_1_full, II_113_1_full, II_114_1_full, II_131_1_full, II_132_1_full, II_292_1_full, II_297_1_full, II_298_1_full, II_472_1_full, II_924_1_full, II_931_1_full, II_940_1_full, II_952_1_full, II_1345_1_full, II_1346_1_full, II_1351_1_full, II_1352_1_full]\n",
    "stations_grace = [II_112_1_grace, II_113_1_grace, II_114_1_grace, II_131_1_grace, II_132_1_grace, II_292_1_grace, II_297_1_grace, II_298_1_grace, II_472_1_grace, II_924_1_grace, II_931_1_grace, II_940_1_grace, II_952_1_grace, II_1345_1_grace, II_1346_1_grace, II_1351_1_grace, II_1352_1_grace]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data_for_station(station):\n",
    "  data_path = \"data/network_input\"\n",
    "  dataset_path = os.path.join(data_path, station)\n",
    "  data = pd.read_pickle(dataset_path)\n",
    "  ata_arr = data.to_numpy()\n",
    "\n",
    "  feat_data = data.loc[:, data.columns != \"target_value\"]\n",
    "  target_data = data.loc[:, data.columns == \"target_value\"]\n",
    "\n",
    "  feat_arr = feat_data.to_numpy()\n",
    "  target_arr = target_data.to_numpy()\n",
    "\n",
    "  target_arr = np.array(target_arr, dtype=np.float32).reshape(-1, 1)\n",
    "  data_arr_2 = []\n",
    "  for row in feat_arr:\n",
    "      row = np.vstack(row)\n",
    "      data_arr_2.append(row)\n",
    "\n",
    "  target_arr_2 = []\n",
    "  for row in target_arr:\n",
    "      row = np.hstack(row)\n",
    "      for item in row:\n",
    "          target_arr_2.append(item)\n",
    "  data_arr_2 = np.array(data_arr_2, dtype=np.float32)\n",
    "  data_flatten = np.array([row.flatten() for row in data_arr_2])\n",
    "\n",
    "  seq_len = 4\n",
    "  sequences = []\n",
    "  targets = []\n",
    "  flat_seq = []\n",
    "  flat_targets = []\n",
    "\n",
    "  for i in range(len(data_flatten) - seq_len + 1):\n",
    "          sequences.append(data_flatten[i:i + seq_len])  # Wyłączenie ostatniej kolumny (target) z sekwencji\n",
    "          targets.append(np.array([target_arr_2[i + seq_len -1]]))\n",
    "          flat_seq.append(data_flatten[i:i + seq_len].flatten())  # Wyłączenie ostatniej kolumny (target) z sekwencji\n",
    "          flat_targets.append(np.array([target_arr_2[i + seq_len-1]]).flatten())\n",
    "\n",
    "  sequences = np.array(sequences, dtype=np.float32)\n",
    "  targets = np.array(targets, dtype=np.float32)\n",
    "\n",
    "  flat_seq = np.array(flat_seq, dtype=np.float32)\n",
    "  flat_targets = np.array(flat_targets, dtype=np.float32)\n",
    "\n",
    "  train_sequences = sequences[:int(sequences.shape[0] * 0.7)]\n",
    "  train_targets = targets[:int(targets.shape[0] * 0.7)]\n",
    "  test_sequences = sequences[int(sequences.shape[0] * 0.7):]\n",
    "  test_targets = targets[int(targets.shape[0] * 0.7):]\n",
    "\n",
    "  train_flat_sequences = flat_seq[:int(flat_seq.shape[0] * 0.7)]\n",
    "  train_flat_targets = flat_targets[:int(flat_targets.shape[0] * 0.7)]\n",
    "  test_flat_sequences = flat_seq[int(flat_seq.shape[0] * 0.7):]\n",
    "  test_flat_targets = flat_targets[int(flat_targets.shape[0] * 0.7):]\n",
    "\n",
    "  data_tensor = torch.tensor(train_sequences, dtype=torch.float32)\n",
    "  target_tensor = torch.tensor(train_targets, dtype=torch.float32)\n",
    "\n",
    "  test_data_tensor = torch.tensor(test_sequences, dtype=torch.float32)\n",
    "  test_target_tensor = torch.tensor(test_targets, dtype=torch.float32)\n",
    "\n",
    "  return data_tensor, target_tensor, test_data_tensor, test_target_tensor, train_flat_sequences, train_flat_targets, test_flat_sequences, test_flat_targets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_xgb(train_flat_sequences, train_flat_targets, test_flat_sequences):\n",
    "    xgb_model = xgb.XGBRegressor()\n",
    "    trained_model = xgb_model.fit(train_flat_sequences, train_flat_targets)\n",
    "    return trained_model.predict(train_flat_sequences), trained_model.predict(test_flat_sequences)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def denormalize_data(data, min, max):\n",
    "    return data * (max - min) + min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, station, denormalize = False):\n",
    "    station_name = station\n",
    "    if \"full\" in station:\n",
    "        station_name = station.replace(\"full_\", \"\")\n",
    "    if \"grace\" in station:\n",
    "        station_name = station.replace(\"grace_\", \"\")\n",
    "        \n",
    "    normalization_data = pd.read_pickle(os.path.join(\"data\", \"normalization\", \"normalization_values_\" + station_name))\n",
    "    train_data_tensor, train_target_tensor, test_data_tensor, test_target_tensor, train_flat_sequences, train_flat_targets, test_flat_sequences, test_flat_targets = prepare_data_for_station(station)\n",
    "    \n",
    "    train_ds = CustomDataset(train_data_tensor, train_target_tensor)\n",
    "    test_ds = CustomDataset(test_data_tensor, test_target_tensor)\n",
    "\n",
    "    train_dataloader = DataLoader(train_ds, batch_size=len(train_ds), shuffle=False)\n",
    "    test_dataloader = DataLoader(test_ds, batch_size=len(test_ds), shuffle=False)\n",
    "    \n",
    "    model.cpu()\n",
    "    \n",
    "    y_true = []\n",
    "    y_train_pred = []\n",
    "    y_test_pred = []\n",
    "    y_test_true = []\n",
    "    model.eval()\n",
    "\n",
    "    idx = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_x, batch_y in train_dataloader:\n",
    "            y_true += batch_y.tolist()\n",
    "            y_train_pred += model(batch_x).tolist()\n",
    "        idx = len(y_train_pred)\n",
    "        for batch_x, batch_y in test_dataloader:\n",
    "            trues = batch_y.tolist()\n",
    "            y_true += trues\n",
    "            y_test_true += trues\n",
    "            preds = model(batch_x).tolist()                \n",
    "            y_train_pred += preds\n",
    "            y_test_pred += preds\n",
    "            break\n",
    "\n",
    "    print(idx)\n",
    "    grace_dates_dir = \"data/grace_dates.pickle\"\n",
    "    with open(grace_dates_dir, 'rb') as f:\n",
    "        grace_dates = pickle.load(f)\n",
    "    \n",
    "    data_results = pd.DataFrame({\n",
    "        \"date\": grace_dates[:len(y_true)],\n",
    "        \"target\": y_true,\n",
    "        \"pred\": y_train_pred\n",
    "    })\n",
    "\n",
    "    data_results[\"date\"] = pd.to_datetime(data_results[\"date\"])\n",
    "    data_results[\"target\"] = data_results[\"target\"].apply(lambda x: x[0])\n",
    "    data_results[\"pred\"] = data_results[\"pred\"].apply(lambda x: x[0])\n",
    "    \n",
    "\n",
    "    types = [\"train\" if i < idx else \"test\" for i in range(len(data_results))]\n",
    "    data_results[\"type\"] = types\n",
    "\n",
    "    train_forecasts, test_forecasts = train_xgb(train_flat_sequences, train_flat_targets, test_flat_sequences)\n",
    "\n",
    "    if denormalize:\n",
    "        min_val = normalization_data.iloc[0][\"min\"]\n",
    "        max_val = normalization_data.iloc[0][\"max\"]\n",
    "        data_results[\"target\"] = data_results[\"target\"].apply(lambda x: denormalize_data(x, min_val, max_val))\n",
    "        data_results[\"pred\"] = data_results[\"pred\"].apply(lambda x: denormalize_data(x, min_val, max_val))\n",
    "        y_test_true = [denormalize_data(x[0], min_val, max_val) for x in y_test_true]\n",
    "        y_test_pred = [denormalize_data(x[0], min_val, max_val) for x in y_test_pred]\n",
    "        train_forecasts = [denormalize_data(x, min_val, max_val) for x in train_forecasts]\n",
    "        test_forecasts = [denormalize_data(x, min_val, max_val) for x in test_forecasts]\n",
    "        test_flat_targets = [denormalize_data(x, min_val, max_val) for x in test_flat_targets]\n",
    "        \n",
    "\n",
    "    mse = mean_squared_error(y_test_true, y_test_pred)\n",
    "    mae = mean_absolute_error(y_test_true, y_test_pred)\n",
    "    \n",
    "    xgb_mse = mean_squared_error(test_flat_targets, test_forecasts)\n",
    "    xgb_mae = mean_absolute_error(test_flat_targets, test_forecasts)\n",
    "    \n",
    "    data_results[\"xgb\"] = np.concatenate((train_forecasts, test_forecasts))\n",
    "\n",
    "    data_results[\"date\"] = pd.to_datetime(data_results['date'])\n",
    "    data_results.index = data_results[\"date\"]\n",
    "    \n",
    "    station_name = station[:-7]    \n",
    "\n",
    "    print()\n",
    "    print(\"--------------------\")\n",
    "    print(f\"Station: {station_name}\")\n",
    "    print(f\"LSTM MSE: {mse:.4f}\")\n",
    "    print(f\"LSTM MAE: {mae:.4f}\")\n",
    "\n",
    "    print(f\"XGB MSE: {xgb_mse:.4f}\")\n",
    "    print(f\"XGB MAE: {xgb_mae:.4f}\")\n",
    "\n",
    "    ax = data_results[: \"2017-06-11\"].plot(kind = \"line\", x = \"date\", y = \"target\", c = \"blue\", style = \"-\", label = \"Target\")\n",
    "    data_results[\"2018-06-16\" :].plot(kind = \"line\", x = \"date\", y = \"target\", c = \"blue\", style = \"-\", ax = ax, label = \"_nolegend_\")\n",
    "\n",
    "    data_results[data_results[\"type\"] == \"train\"][: \"2017-06-11\"].plot(kind = \"line\", x = \"date\", y = \"pred\", ax = ax, c = \"green\", style = \"-\", label = \"LSTM Train set\")\n",
    "    data_results[data_results[\"type\"] == \"train\"][\"2018-06-16\" :].plot(kind = \"line\", x = \"date\", y = \"pred\", ax = ax, c = \"green\", style = \"-\", label = \"_nolegend_\")\n",
    "\n",
    "    data_results[data_results[\"type\"] == \"test\"][: \"2017-06-11\"].plot(kind = \"line\", x = \"date\", y = \"pred\", ax = ax, c = \"red\", style = \"-\", label = \"LSTM Test set\")\n",
    "    data_results[data_results[\"type\"] == \"test\"][\"2018-06-16\" :].plot(kind = \"line\", x = \"date\", y = \"pred\", ax = ax, c = \"red\", style = \"-\", label = \"_nolegend_\")\n",
    "\n",
    "    data_results[data_results[\"type\"] == \"train\"][: \"2017-06-11\"].plot(kind = \"line\", x = \"date\", y = \"xgb\", ax = ax, c = \"brown\", style = \"-\", label = \"XGB Train set\")\n",
    "    data_results[data_results[\"type\"] == \"train\"][\"2018-06-16\" :].plot(kind = \"line\", x = \"date\", y = \"xgb\", ax = ax, c = \"brown\", style = \"-\", label = \"_nolegend_\")\n",
    "\n",
    "    data_results[data_results[\"type\"] == \"test\"][: \"2017-06-11\"].plot(kind = \"line\", x = \"date\", y = \"xgb\", ax = ax, c = \"orange\", style = \"-\", label = \"XGB Test set\")\n",
    "    data_results[data_results[\"type\"] == \"test\"][\"2018-06-16\" :].plot(kind = \"line\", x = \"date\", y = \"xgb\", ax = ax, c = \"orange\", style = \"-\", label = \"_nolegend_\")\n",
    "\n",
    "\n",
    "    #plt.plot(y_true, label=\"Target\")\n",
    "    #plt.plot(y_pred, label=\"LSTM\")\n",
    "    #plt.plot(test_forecasts, label=\"XGB\")\n",
    "    ax.xaxis.set_major_locator(mdates.YearLocator())\n",
    "    plt.legend()\n",
    "    #plt.title(f\"Station: {station_name}, LSTM MSE: {mse:.4f}, LSTM MAE: {mae:.4f}, XGB_MSE = {xgb_mse:.4f}, XGB_MAE = {xgb_mae:.4f}\")\n",
    "    #plt.title(f\"Station: {station_name}, LSTM MSE: {mse:.4f}, LSTM MAE: {mae:.4f}\")\n",
    "\n",
    "    plt.savefig(os.path.join(\"data\", \"plots\", f\"{station_name}.png\"))\n",
    "    plt.show()\n",
    "\n",
    "    return data_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data, target):\n",
    "        self.data = data\n",
    "        self.target = target\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index], self.target[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(torch.nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = torch.nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = torch.nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (15,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station = II_297_1_full\n",
    "model_path = os.path.join(models_dir, \"model_\" + station[:-6] + \"pt\")\n",
    "model = torch.load(model_path)\n",
    "test_model(model, station, denormalize = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
